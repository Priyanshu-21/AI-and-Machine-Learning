{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf934902",
   "metadata": {},
   "source": [
    "### Implementation of backpropagation Algorithm \n",
    "- Implementation of the XOR Gate \n",
    "1. Initialize the weights and bias of the model \n",
    "2. Calculate model prediction output and Error using Forward propagation \n",
    "3. Now update weights and bias of each neuron in the model using back-propagation to optimize the model \n",
    "4. Repeat step 2 - 3 until,\n",
    "    - Until epoch or number of iterations are reached \n",
    "    - Until model matches estimated error threshold. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5404c7a",
   "metadata": {},
   "source": [
    "### Objective \n",
    "* Train a Neural Network to Solve the XOR Problem\n",
    "* Implement Backpropagation for Neural Network Training\n",
    "* Demonstrate the Use of Activation Functions\n",
    "* Understand the Learning Process Over Multiple Epochs\n",
    "* Demonstrate Weight and Bias Adjustments via Gradient Descent\n",
    "* Evaluate the Model's Performance After Training\n",
    "* Monitor and Analyze the Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2a868b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c8c894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialization of weights, bias and structure of neural network \n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]).T\n",
    "d = np.array([0, 1, 1, 0]) # Expected output \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a59cf09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_neural_network():\n",
    "    input_size = 2 #(x1 and x2)\n",
    "    hidden_size = 2\n",
    "    output_size = 1\n",
    "    \n",
    "    #Number of iterations and learning rate\n",
    "    epochs = 20000\n",
    "    lr = 0.1\n",
    "\n",
    "    #Defining structure of XOR neural network \n",
    "    w1 = np.random.randn(input_size, hidden_size) / 2 #2 * 2 matrix\n",
    "    w2 = np.random.randn(hidden_size, output_size) / 2 #2 * 1 matrix\n",
    "\n",
    "    b1 = np.random.randn(hidden_size, 1) / 2 #2 * 1 matrix \n",
    "    b2 = np.random.randn(output_size, 1) / 2 #1 * 1 matrix \n",
    "\n",
    "    return w1, w2, b1, b2, epochs, lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fabfd94c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 4 is different from 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m d_z2 = a2\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m#At layer 1\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m d_a1 = \u001b[43mw2\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43md_z2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m \n\u001b[32m     30\u001b[39m d_z1 = d_a1 * (a1 * (\u001b[32m1\u001b[39m - a1))\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m#Modifying weight and bias at each epoch \u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 4 is different from 1)"
     ]
    }
   ],
   "source": [
    "#Training neural Netowrk, calculating and adjusting weights and bias \n",
    "errors_list = []\n",
    "\n",
    "#Activation Function \n",
    "sigma = lambda z: 1 / (1 + np.exp(-z))\n",
    "\n",
    "#calling to get initialized strucutre of neural network \n",
    "w1, w2, b1, b2, epochs, lr = initialize_neural_network()\n",
    "\n",
    "#Training of neural network \n",
    "for epoch in range(epochs):\n",
    "\n",
    "    #Forward Propagation to calculate weights, bias and error \n",
    "    z1 = w1 @ X + b1\n",
    "    a1 = sigma(z1)\n",
    "    \n",
    "    z2 = w2.T @ a1 + b2\n",
    "    a2 = sigma(z2)\n",
    "\n",
    "    #Calculating model Error estimation \n",
    "    error = d - a2 \n",
    "\n",
    "    #Backpropagation to update weights and bias \n",
    "    #At layer 2 \n",
    "    d_a2 = error * (a2 * (1 - a2))\n",
    "    d_z2 = a2\n",
    "\n",
    "    #At layer 1\n",
    "    d_a1 = w2 @ d_z2.T \n",
    "    d_z1 = d_a1 * (a1 * (1 - a1))\n",
    "\n",
    "    #Modifying weight and bias at each epoch \n",
    "    w2 += lr * d_z2 @ a1.T\n",
    "    b2 += lr * np.sum(d_z2, axis= 1, keepdims= True) \n",
    "\n",
    "    w1 += lr * d_z1 @ X.T\n",
    "    b1 += lr * np.sum(d_z1, axis= 1, keepdims= True)\n",
    "\n",
    "    #Keeping error at each 1000 iterations \n",
    "    if ((epoch + 1) % 1000 == 0):\n",
    "        print('Error at {} iterations is: {}'.format(epoch, np.average(abs(error))))\n",
    "        errors_list.append(np.average(abs(error)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d26320",
   "metadata": {},
   "source": [
    "### TODO: - \n",
    "1. Fix this matrix multiplicaiton error. \n",
    "2. Test out model in the testing inputs \n",
    "3. Visualize Error list using plots "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-and-Machine-Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
